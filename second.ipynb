{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S \n",
      "A \n",
      "MOUSTACHIR \n",
      "NOTICE D'INFORMATION \n",
      "Augmentation de capital par √©mission de nouvelles actions \n",
      "Nombres d‚Äôactions offertes \n",
      ": 125 000 actions \n",
      "Prix de cession \n",
      ": 760 DA / Montant de I√©mission \n",
      ": 94 437 500.00 \n",
      "P√©riode de souscription \n",
      ": du 01/12/2024 au 31/12/2024 \n",
      "Promoteur en Bourse et Interm√©diaire en Op√©ration de Bourse (10B) \n",
      "Chef de file \n",
      "Interm√©diaires en Op√©ration de Bourse (10B) \n",
      "Membres du Syndicat de placement \n",
      "B \n",
      "mm== \n",
      " alBaraka \n",
      "Visa COSOB n¬∞2024/04 du 23/10/2024 \n",
      "\n",
      "\" Moustachir \n",
      "- j \n",
      "Notice D'information \n",
      "AVERTISSEMENT \n",
      "Le visa de \n",
      "la commission ne peut √©tre assimil√© \n",
      "a une recommandation de \n",
      "souscription ou d'achat des titres proposes. \n",
      "1l ne comporte aucun jugement, aucune appr√©ciation sur I'op√©ration projet√©e. \n",
      "1l v√©rifie seulement que les informations fournies par la notice d'information \n",
      "vis√©e paraissent v√©ridiques et suffisantes pour que l'investisseur potentiel puisse \n",
      "fonder sa d√©cision. \n",
      "L'attention \n",
      "des \n",
      "investisseurs \n",
      "potentiels \n",
      "est \n",
      "attir√©e \n",
      "sur \n",
      "le \n",
      "fait \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Chemin vers le fichier PDF\n",
    "pdf_path = \"data/Copy of ÿßŸÑŸÖÿ∞ŸÉÿ±ÿ© ÿßŸÑÿ•ÿπŸÑÿßŸÖŸäÿ© SPA MOUSTACHIR-1.pdf\"\n",
    "\n",
    "# Lire le fichier PDF\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Extraire le texte de toutes les pages\n",
    "text = \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "# Afficher les premi√®res lignes pour v√©rifier\n",
    "print(text[:1000])  # Affiche les 1000 premiers caract√®res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 0: S \n",
      "A \n",
      "MOUSTACHIR \n",
      "NOTICE D'INFORMATION \n",
      "Augmentation de capital par √©mission de nouvelles actions \n",
      "Nombres d‚Äôactions offertes \n",
      ": 125 000 actions \n",
      "Prix de cession \n",
      ": 760 DA / Montant de I√©mission \n",
      ": 94\n",
      "Section 1: \n",
      "1.1.2. Montant de I'op√©ration ....... \n",
      "\n",
      "Section 2: 1.1.4. Produit brut et estimation du produit net de la cessiol \n",
      "Section 3: \n",
      "1.1.4.1. Produit brut de la cession \n",
      "\n",
      "Section 4: . \n",
      "Section 5: \n",
      "1.1.4.2. Produit net de la cession... \n",
      "\n",
      "Section 6: 1.1.4.3. Utilisation du produit net de la cession \n",
      "Section 7: \n",
      "1.1.5. Charges relatives a |'op√©ration \n",
      "\n",
      "Section 8: 1.1.6. Jouissance des titres c√©d√©s \n",
      "Section 9: \n",
      "1.1.7. P√©riode de souscription \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Diviser le texte par les titres en rep√©rant des mots-cl√©s comme \"Chapitre\", \"Services\", etc.\n",
    "sections = re.split(r'(\\n[0-9.]+[-\\s].+?\\n)', text)\n",
    "\n",
    "# Afficher les sections trouv√©es\n",
    "for i, section in enumerate(sections[:10]):  # Affiche les 10 premi√®res parties\n",
    "    print(f\"Section {i}: {section[:200]}\")  # Affiche les 200 premiers caract√®res par section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es enregistr√©es sous format JSON !\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Exemple de structure JSON\n",
    "data = {\n",
    "    \"services\": {},\n",
    "    \"achat_actions\": {},\n",
    "    \"partenariats\": {},\n",
    "}\n",
    "\n",
    "# Remplir le dictionnaire avec des extraits pertinents du texte (manuel ou via regex)\n",
    "data[\"services\"][\"consulting\"] = \"...\"\n",
    "data[\"achat_actions\"][\"processus\"] = \"...\"\n",
    "data[\"partenariats\"][\"expansion\"] = \"...\"\n",
    "\n",
    "# Sauvegarder le fichier JSON\n",
    "with open(\"data/moustachir_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"‚úÖ Donn√©es enregistr√©es sous format JSON !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Charger le mod√®le T5\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Mod√®le l√©ger (tu peux essayer \"t5-base\" ou \"t5-large\" si besoin)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Tester le mod√®le\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1637\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1637\u001b[0m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1625\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1623\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger le mod√®le T5\n",
    "model_name = \"t5-small\"  # Mod√®le l√©ger (tu peux essayer \"t5-base\" ou \"t5-large\" si besoin)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Tester le mod√®le\n",
    "def generate_answer(prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    output = model.generate(input_ids)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Test avec une question\n",
    "question = \"Comment acheter des actions Moustachir ?\"\n",
    "prompt = f\"R√©ponds √† la question : {question}\"\n",
    "response = generate_answer(prompt)\n",
    "\n",
    "print(\"üü¢ R√©ponse :\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test123...\n",
      "test...1\n",
      "test...1\n",
      "test...1\n"
     ]
    }
   ],
   "source": [
    "print(\"test123...\")\n",
    "for i in [1,2,3]:\n",
    "    print(\"test...1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
